#!/usr/bin/env python3
# tested on python2.7 and python3.6

import logging, sys, optparse, os, io, json
from collections import defaultdict, OrderedDict
from os.path import join, basename, dirname, isfile, isdir, expanduser
from datetime import datetime
import csv, zipfile
import textwrap
from io import StringIO # python2.6 and 3
import requests # not installed? run "pip install requests"

# all possible values for the --format option
allFmts = ["ncbi", "ncbi-sep", "ncbi-ftp", "gisaid", "ena"]

config = {
    # three-leter country abbreviation
    "country" : "USA",
    # common or scientific name of host
    "ncbi-host" : "human",
    "ncbi-genome" : "SARS-CoV-2",

    # bogus values:
    # overwritten by ~/.multiSub.conf, these bogus values are only there so the script can run 
    # without a config file

    # for the GISAID file
    "gisaidUser" : "gisaidTest",
    "gisaidLocation" : "North America / USA / California / Santa Cruz",
    "gisaid_host" : "Human",
    "gisaid_technology" : "Illumina NextSeq 550",
    "gisaid_assembly_method" : "",
    "gisaid_orig_lab" : "UCSC Genomics Institute",
    "gisaid_orig_lab_addr" : "1156 High Street. Santa Cruz, CA 95064",
    # for the NCBI Submission XML file
    "ncbiUser" : "testUser",
    "contact" : ("Doe", "John", "D"),
    "email" : "test@test.com",
    "phone" : "",
    "authors" : [
        # format: (lastname, firstname, middle initial)
        ("Haussler","David", ""),
        ("Haeussler","Max", ""),
    ],
    "affiliation" : {
        "affil" : "University of California, Santa Cruz",
        "div" : "Genomics Institute",
        "city" : "Santa Cruz",
        "sub" : "CA",
        "country" : "USA",
        "street" : "1156 High Street, MS Genomics Institute",
        "postal-code" : "95064"
    }
}

configDone = False

def getConfig():
    " return config as dict "
    global config
    global configDone
    if not configDone:
        homeDir = os.path.expanduser('~')
        cfgFname = join(homeDir, ".multiSub.conf")
        if isfile(cfgFname):
            exec(io.open(cfgFname).read(), config)
        else:
            logging.info("%s does not exist. Using default values. Consider running 'curl https://hgwdev.gi.ucsc.edu/~max/multiSub/multiSub.conf > ~/.multiSub.conf'" % cfgFname)
        configDone = True
    return config


# ==== functions =====
def parseArgs():
    " setup logging, parse command line arguments and options. -h shows auto-generated help page "
    parser = optparse.OptionParser("""usage: %prog [options] [command] [arguments]- prepare genbank submission file
    Commands:
        conv faFname tsvFname outDir - converts a fasta + tsv to NCBI format in outDir
        put outDir - uploads the files in outDir to NCBI

    Examples:
        
        multiSub convert seqs.fa seqs.tsv mySub - convert fasta+tsv to NCBI format in mySub/
        multiSub up-ncbi mySub - upload NCBI files in mySub to NCBI's FTP server as test submission (add --prod if final)

    """)

    parser.add_option("-d", "--debug", dest="debug",
        action="store_true", help="show debug messages")
    parser.add_option("-s", "--skip", dest="skipFile",
        action="store", help="file with at least one column with the sequence "
        "identifier of sequences to remove. Can be the raw NCBI error report text file. These "
        "sequences and their annotations will be skipped.")
    #parser.add_option("", "--skipFa", dest="skipFa", action="store",
        #help="file to write skipped sequences to.")
    parser.add_option("-f", "--format", dest="format", action="store",
        default="all",
        help="comma-separated list of output formats to generate. Can be: %s or 'all'" % ",".join(allFmts))
    parser.add_option("", "--prod", dest="prod", action="store_true", help="For up-ncbi and up-ena: use the Production upload server, not Testing")
    parser.add_option("", "--test", dest="test", action="store_true", help="run tests")
    (options, args) = parser.parse_args()

    if options.test:
        import doctest
        doctest.testmod()
        sys.exit(1)

    if args==[]:
        parser.print_help()
        exit(1)

    if options.debug:
        logging.basicConfig(level=logging.DEBUG)
        logging.getLogger().setLevel(logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
        logging.getLogger().setLevel(logging.INFO)

    return args, options
# ----------- main --------------
def openFile(fname, mode="rt"):
    """ opens file, recognizing stdout and stdin and none"""
    if hasattr(fname, "read") or hasattr(fname, "write"):
        return fname
    elif fname.endswith(".gz"):
        fh = gzip.open(fname, mode)
    elif fname=="stdout":
        fh = sys.stdout
    elif fname=="stdin":
        fh = sys.stdin
    elif fname==None or fname.lower()=="none":
        fh = None
    else:
        fh = io.open(fname, mode)
    return fh

def parseFastaId(line):
    " return sequence ID given fasta seq Id line "
    seqId=line.strip(">").strip()
    if "|" in seqId:
        seqId = seqId.split("|")[0]
    return seqId

def parseFasta(fname):
  """ Generator: yields sequences as tuple (id, sequence) """
  logging.info("Reading fasta file %s" % fname)
  if hasattr(fname, 'read'):
      ifh = fname
  elif fname=="stdin":
      ifh=sys.stdin
  elif fname.endswith(".gz"):
      ifh=gzip.open(fname)
  else:
      ifh=io.open(fname, "rt", encoding="utf8")

  seqLines = []
  lastId = None

  for line in ifh:
          line = line.rstrip("\n\r")
          if line=="" or line.startswith("#"):
              continue
          elif not line.startswith(">"):
             seqLines.append(line.replace(" ","").strip())
             continue
          else:
             if len(seqLines)!=0: # on first >, seq is empty
                   faseq = (lastId, "".join(seqLines))
                   lastId = parseFastaId(line)
                   seqLines = []
                   yield faseq
             else:
                   if lastId!=None:
                       sys.stderr.write("warning: when reading fasta file: empty "
                           "sequence, id: %s\n" % line)
                   lastId = parseFastaId(line)
                   seqLines=[]

  # if it's the last sequence in a file, loop will end on the last line
  if len(seqLines)!=0:
      faseq = (lastId, "".join(seqLines))
      yield faseq
  else:
      yield (None, None)

def readMetaGisaid(fname):
    " read meta data in GISAID format and convert to our internal dictionary: meta[isolate] -> dict with date -> date  "
    from xlrd import open_workbook
    book = open_workbook(fname,on_demand=True)
    sheet = book.sheet_by_index(1)
    headers = [sheet.col_values(i)[0] for i in range(sheet.ncols) if sheet.col_values(i)[0]]

    dateIdx = headers.index("covv_collection_date")
    isolateIdx = headers.index("covv_virus_name")
    locIdx = headers.index("covv_location")

    meta = dict()
    for row_idx in range(2, sheet.nrows):    # Iterate through rows
        row = []
        for cell in sheet.row(row_idx):
            row.append(cell.value)
        date = row[dateIdx]
        isolate = row[isolateIdx]
        meta[isolate] = OrderedDict()
        meta[isolate]["isolate"] = isolate
        meta[isolate]["date"] = date
        meta[isolate]["country"] = row[locIdx].split("/")[1].strip()
        meta[isolate]["location"] = row[locIdx]

    return meta

def errAbort(msg):
    logging.error(msg)
    sys.exit(1)

def checkMeta(meta):
    " throw error if something is malformed in meta data "
    for seqId, m in meta.items():
        if not "isolate" in m.keys():
            errAbort("Meta data row for '%s' does not contain an 'isolate' field" % seqId)

        if not "date" in m:
            errAbort("Meta data row for '%s' does not contain a date field" % seqId)
        else:
            year, month, day = m["date"].split("-") # date format is 2019-12-30
            year = int(year)
            month = int(month)
            day = int(day)
            note = " Note that input date must look like 2019-12-30"
            if not year > 2019:
                errAbort(("Meta data row for '%s': year must be > 2019."+note) % seqId)
            if not month > 0 and not month < 13 :
                errAbort(("Meta data row for '%s': month must be > 0 and < 13."+note) % seqId)
            if not day > 0 and not day <= 31 :
                errAbort(("Meta data row for '%s': day must be > 0 and <= 31."+note) % seqId)


def readMeta(fname):
    """ read meta data in format csv, tsv or xls. return as dict with 'seqId' -> OrderedDict of 'key':'value'
    Standardize field names to: date and isolate
    """
    if fname.endswith(".xls"):
        meta = readMetaGisaid(fname)
    else:
        meta = readMetaText(fname)

    checkMeta(meta)
    return meta

def readMetaText(fname):
    """ read csv/tsv table with sequence meta data and return as dict with 'seqId' -> OrderedDict of 'key':'value'
    Current field names are: "date" and "isolate".
    Standardize field names to: date and isolate.
    """
    headers, rows = parseTable(fname)

    meta = dict()
    lNo = 0
    for row in rows:
        lNo += 1
        if len(row) != len(headers):
            logging.error("Line %d: number of fields is not identical to number of header fields. "
                "Headers are: %s, fields are %s" % (lNo, repr(row), repr(headers)))
            sys.exit(0)

        seqId = row[0]

        d = OrderedDict()

        # if the first field is "isolate", add it here again:
        # The genbank files that we create use 'isolate' as the first field
        if not "isolate" in d and headers[0]=="isolate":
            d["isolate"] = seqId

        for colIdx in range(1, len(headers)):
            key = headers[colIdx]
            d[key] = row[colIdx]
        meta[seqId] = d


    return meta

def parseTable(fname):
    " read csv or tsv, return (list headers, list of row-tuples) "
    logging.info("Parsing tsv or csv file '%s'" % fname)

    sep = "\t"
    if ".csv" in fname:
        sep = ","
    if ".tsv" in fname:
        sep = "\t"

    headers = None
    rows = []

    with openFile(fname) as ifh:
        # sniffer was too unreliable on real files
        #sample = ifh.read(80)
        #deduced_dialect = csv.Sniffer().sniff(sample)
        #reader = csv.reader(ifh, dialect=deduced_dialect)
        reader = csv.reader(ifh, delimiter=sep, quoting=csv.QUOTE_ALL)
        for row in reader:
            if headers is None:
                headers = row
            else:
                if len(row)==0 or row[0]=="":
                    continue
                rows.append(row)
    return headers, rows

def trimSeq(seqId, seq):
    """ remove initial and final Ns from seq, for Genbank
    >>> trimSeq("test", "NNNACTGNNN")
    (6, 'ACTG')
    >>> trimSeq("test", "ACTGN")
    (1, 'ACTG')
    >>> trimSeq("test", "NACTG")
    (1, 'ACTG')
    """
    lowSeq = seq.lower()
    trimCount = 0

    startPos = 0
    while lowSeq[startPos]=="n":
        startPos+=1
        trimCount += 1

    endPos = len(seq)-1
    while lowSeq[endPos]=="n":
        endPos-=1
        trimCount += 1

    if trimCount != 0:
        logging.debug("Trimmed %d starting and %d ending nucleotides from seq %s "
            "(total: %d)" % (startPos, len(seq)-endPos-1, seqId, trimCount))
    return trimCount, seq[startPos:endPos+1]

def writeFasta(seqs, ofh):
    " write list of (id, seq) to ofh "
    outCount = 0
    for seqId, seq in seqs:
        ofh.write(u">")
        ofh.write(seqId)
        ofh.write(u"\n")

        lines = [seq[i:i + 60] for i in range(0, len(seq), 60)]
        ofh.write("\n".join(lines))
        ofh.write(u"\n")
        outCount += 1

    if "name" in dir(ofh):
        logging.info("Wrote %d sequences to %s" % (outCount, ofh.name))

def writeMetaTsv(meta, ofh):
    " write meta information to a tsv file. Assume that all meta keys are identical. "
    seqId0 = list(meta.keys())[0]
    headers = meta[seqId0].keys()
    ofh.write(u"\t".join(headers))
    ofh.write(u"\n")

    for seqId, metaDict in meta.items():
        assert(headers==metaDict.keys())
        vals = metaDict.values()
        ofh.write(u"\t".join(vals))
        ofh.write(u"\n")

def metaToGenbank(meta):
    " convert meta data to genbank format, return as 'seqId' -> dict of 'key:'value'. Changes only the 'key' strings.  "
    cf = getConfig()

    newMeta = dict()
    for seqId, seqMeta in meta.items():
        if " " in seqId:
            logging.error("Sequence identifier %ss: seqId cannot contain spaces - "
                "skipping this sequence" % repr(seqId))
            continue

        if "[" in seqId or "]" in seqId:
            logging.error("Sequence identifier %s: seqIdcannot contain brackets - "
                "skipping this sequence" % repr(seqId))
            continue

        ns = OrderedDict()

        isolate = seqMeta["isolate"]

        date = seqMeta["date"]
        ns["collection-date"] = date

        if "country" not in seqMeta:
            ns["country"] = cf["country"]
        else:
            ns["country"] = seqMeta["country"]

        ns["host"] = cf["ncbi-host"]

        if not "/" in isolate:
            # ICTV/CDC format see https://github.com/CDCgov/SARS-CoV-2_Sequencing#submitting
            logging.debug("No / found in isolate %s. Generating the ICTV format" % isolate)
            year = date.split("-")[0]
            country = cf["country"]
            host = ns["host"]
            genome = cf["ncbi-genome"]
            isolate = "%s/%s/%s/%s/%s" % (genome, isolate, host, country, year)

        ns["isolate"] = isolate

        newMeta[seqId] = ns

    return newMeta

def makeGenbankTagSeqs(seqs, meta):
    """ merge meta data into seq IDs as []-tags and return a list of (seqId,
    seq)
    """
    trimSeqCount = 0

    newSeqs = []
    for seqId, seq in seqs:
        trimCount, seq = trimSeq(seqId, seq)
        if trimCount != 0:
            trimSeqCount += 1

        seqMeta = meta.get(seqId)

        if seqMeta is None:
            logging.error("Skipping fasta sequence with ID %s - cannot find it "
                "in the annotation table" % repr(seqId))
            continue

        isolate = seqMeta["isolate"]
        title = "Severe acute respiratory syndrome coronavirus 2 " \
                "isolate %s, complete genome" % isolate

        tagsStrs = []
        for key, val in seqMeta.items():
            tagsStrs.append("["+key+"="+val+"]")

        tagStr = " ".join(tagsStrs)
        seqId = "%s %s %s" % (seqId, tagStr, title)

        newSeqs.append( (seqId, seq) )

    return newSeqs

    logging.info("Trimmed starting/ending N-letters from %d sequences" % trimSeqCount)

def writeGenbankTagFa(seqs, meta, gbOutFname):
    """ write sequences to genbank for interactive submission, a single fasta file
    This format saves the annotations directly into the fasta file, so
    you need to upload only a single file.
    """
    gbMeta = metaToGenbank(meta)
    gbSeqs = makeGenbankTagSeqs(seqs, gbMeta)

    with io.open(gbOutFname, "wt") as ofh:
        writeFasta(gbSeqs, ofh)

def filterAll(skipFile, seqs, meta):
    " parse first column from skipFile and remove these seqs and their annotations "
    headers, rows = parseTable(skipFile)
    skipIds = set()
    for row in rows:
        skipIds.add( row[0] )
    logging.info("Read %d sequence IDs from file %s to skip" % (len(skipIds), skipFile))

    newSeqs = []
    skippedSeqs = []
    skipSeqCount = 0
    skipAnnotCount = 0
    for seqId, seq in seqs:
        if seqId in skipIds:
            skipSeqCount +=1
            skippedSeqs.append ( (seqId, seq) )
        else:
            newSeqs.append ( (seqId, seq) )

    newMeta = {}
    skippedMeta = {}
    for key, val in meta.items():
        if key in skipIds:
            skipAnnotCount += 1
            skippedMeta[key] = val
        else:
            newMeta[key] = val

    logging.info("Removed %d sequences and %d annotation rows" % (skipSeqCount, skipAnnotCount) )
    logging.info("%d sequences and %d annotation rows remain" % (len(newSeqs), len(newMeta)) )
    return newSeqs, newMeta, skippedSeqs, skippedMeta

def makeAuthors():
    "return ncbi templatestring for authors "
    cfg = getConfig()
    strs = []
    for au in cfg["authors"]:
       strs.append("""
       {
          name name {
            last "%s",
            first "%s",
            middle "%s",
            initials "",
            suffix "",
            title ""
          }
        },
        """ % (au[0], au[1], au[2]))
    return "\n".join(strs)

def makeTemplate():
    " make genbank ASN.1 submission template and return as string "
    cf = getConfig()

    last = cf["contact"][0]
    first = cf["contact"][1]
    middle = cf["contact"][2]
    email = cf["email"]
    phone = cf["phone"]

    af = cf["affiliation"]
    afUni = af["affil"]
    afDiv = af["div"]
    afCity = af["city"]
    afSub = af["sub"]
    afCountry = af["country"]
    afStreet = af["street"]
    afPostal = af["postal-code"]
    authors = makeAuthors()

    templ = """Submit-block ::= {
  contact {
    contact {
      name name {
        last "%(last)s",
        first "%(first)s",
        middle "%(middle)s",
        initials "",
        suffix "",
        title ""
      },
      affil std {
        affil "%(afUni)s",
        div "%(afDiv)s",
        city "%(afCity)s",
        sub "%(afSub)s",
        country "%(afCountry)s",
        street "%(afStreet)s",
        email "%(email)s",
        phone "%(phone)s",
        postal-code "%(afPostal)s"
      }
    }
  },
  cit {
    authors {
      names std {
        %(authors)s
      affil std {
        affil "%(afUni)s",
        div "%(afDiv)s",
        city "%(afCity)s",
        sub "%(afSub)s",
        country "%(afCountry)s",
        street "%(afStreet)s",
        postal-code "%(afPostal)s"
      }
    }
  },
  subtype new
}
Seqdesc ::= pub {
  pub {
    gen {
      cit "unpublished",
      authors {
        names std {
           %(authors)s
        }
      },
      title "Direct Submission"
    }
  }
}
Seqdesc ::= user {
  type str "Submission",
  data {
    {
    }
  }
}
Seqdesc ::= user {
  type str "Submission",
  data {
    {
      label str "AdditionalComment",
      data str "Submission Title:None"
    }
  }
} """ % locals()
    return templ

def now():
    "returns current time in isoformat, only seconds "
    s = datetime.isoformat(datetime.now(), sep="_").split(".")[0].replace(":", "")
    return s

def makeNcbiSubXml():
    " generate a ncbi submission.xml file "
    # I am not using release dates:
    # <Hold release_date="2024-05-25"/>
    c = getConfig()
    ncbiUser = c["ncbiUser"]
    uniqueId = now()

    xml = """<?xml version="1.0"?>
<Submission>
  <Description>
    <Title>multiSub automated submission</Title>
    <Comment>SARS-CoV-2 test submission</Comment>
    <Organization type="center" role="owner">
      <Name>%(ncbiUser)s</Name>
    </Organization>
  </Description>
  <Action>
    <AddFiles target_db="GenBank">
      <File file_path="submission.zip">
        <DataType>genbank-submission-package</DataType>
      </File>
      <Attribute name="wizard">BankIt_SARSCoV2_api</Attribute>
      <Attribute name="auto_remove_failed_seqs">yes</Attribute>
      <Identifier>
        <SPUID spuid_namespace="ncbi-sarscov2-genbank">%(uniqueId)s</SPUID>
      </Identifier>
    </AddFiles>
  </Action>
</Submission>
    """ % locals()
    return xml

def writeGenbankFtpZip(seqs, meta, zipFname, xmlFname):
    " create fasta/src and xml file for genbank ftp upload "
    # documentation and sample files are here: https://www.ncbi.nlm.nih.gov/viewvc/v1/trunk/submit/public-docs/genbank/SARS-CoV-2/
    gbMeta = metaToGenbank(meta)

    with zipfile.ZipFile(zipFname, "w") as zfh:
        # writing as a string avoids any py2/3 unicode trouble
        with StringIO() as memFh:
            writeFasta(seqs, memFh)
            zfh.writestr("seqs.fsa", memFh.getvalue())

        with StringIO() as memFh:
            writeMetaTsv(gbMeta, memFh)
            zfh.writestr("seqs.src", memFh.getvalue())

        zfh.writestr("seqs.sbt", makeTemplate())

    logging.info("Wrote zipfile %s" % zipFname)

    #xmlFname = join(outDir, "submission.xml")
    with io.open(xmlFname, "wt") as ofh:
        ofh.write( makeNcbiSubXml() )
    logging.info("Wrote genbank XML %s" % xmlFname)

def getFormats(formatStr):
    " return the list of specified output formats. formatStr is a comma separated list "
    outFmts = None
    if formatStr is None or formatStr == "all":
        outFmts = allFmts
    else:
        fmts = formatStr.split(",")
        unknownFmts = set(fmts)-set(allFmts)
        if len(unknownFmts)!=0:
            errAbort("These output formats are not valid: %s" % unknownFmts)
        outFmts = fmts
    return outFmts

def writeGisaidCsv(seqs, meta, seqFn, metaFn):
    " write the seqs and the meta csv in GISAID format "
    # GISAID docs has this sample:
    # submitter,fn,covv_virus_name,covv_type,covv_passage,covv_collection_date,covv_location,covv_a dd_location,covv_host,covv_add_host_info,covv_gender,covv_patient_age,covv_patient_status,cov v_specimen,covv_outbreak,covv_last_vaccinated,covv_treatment,covv_seq_technology,covv_assembl y_method,covv_coverage,covv_orig_lab,covv_orig_lab_addr,covv_provider_sample_id,covv_subm_lab ,covv_subm_lab_addr,covv_subm_sample_id,covv_authors
    #lanman,20200629.gisaid.fa,hCoV-19/England/07/2020,betacoronavirus,Original,2020-03-24,United Kingdom / England,,Human,,unknown,unknown,unknown,unknown,unknown,unknown,unknown, OXFORD_NANOPORE,unknown,unknown,University, "Institute of Microbiology and Infection, University-Street, UK",BIRM-5E407,COVID-19 Genomics UK (COG-UK) Consortium,United Kingdom,LON-07, "Jane Doe, John Doe"
    # rewrite seqs to use isolate name
    newSeqs = []
    for seqId, seq in seqs:
        isolate = meta[seqId]["isolate"]
        newSeqs.append((isolate, seq))
    writeFasta(newSeqs, io.open(seqFn, "wt"))

    cf = getConfig()
    metaFh = io.open(metaFn, "wt")
    metaFh.write("submitter,fn,covv_virus_name,covv_type,covv_passage,covv_collection_date,covv_location,covv_add_location,covv_host,covv_add_host_info,covv_gender,covv_patient_age,covv_patient_status,covv_specimen,covv_outbreak,covv_last_vaccinated,covv_treatment,covv_seq_technology,covv_assembly_method,covv_coverage,covv_orig_lab,covv_orig_lab_addr,covv_provider_sample_id,covv_subm_lab ,covv_subm_lab_addr,covv_subm_sample_id,covv_authors\n")

    for seqId, metaDict in meta.items():
        submitter = cf["gisaidUser"]
        fn = "gisaid.fa"
        name = metaDict["isolate"]
        vType = "betacoronavirus"
        passage = "Original"
        date = metaDict["date"]
        if "location" in metaDict:
            location = metaDict["location"]
        else:
            location = cf["gisaidLocation"]
        addLocation = ""
        host = "Human"
        addHost = ""
        gender = "unknown"
        age = "unknown"
        status = "unknown"
        specimen = ""
        outbreak = ""
        last_vaccinated = ""
        treatment = ""
        if "gisaid_technology" in cf:
            technology = cf["gisaid_technology"]
        else:
            technology = "Illumina NextSeq 550"

        if "gisaid_assembly_method" in cf:
            assembly_method = cf["gisaid_assembly_method"]
        else:
            assembly_method = ""

        coverage = ""
        orig_lab = cf["gisaid_orig_lab"]
        orig_lab_addr = cf["gisaid_orig_lab_addr"]
        sampleId = ""
        subm_lab = cf["gisaid_orig_lab"]
        subm_lab_addr = cf["gisaid_orig_lab_addr"]
        subm_lab_sample_id = ""

        auStrs = []
        for au in cf["authors"]:
            last, first, middle = au
            if middle!="":
                auStr = "%s %s %s" % (first, middle, last)
            else:
                auStr = "%s %s" % (first, last)
            auStrs.append(auStr)
        authors = u", ".join(auStrs)

        row = [submitter, fn, name, vType, passage, date, location, addLocation, host, \
                addHost, gender, age, status, specimen, outbreak, last_vaccinated, treatment, \
                technology, assembly_method, coverage, '"'+orig_lab+'"', '"'+orig_lab_addr+'"', \
                sampleId, '"'+subm_lab+'"', '"'+subm_lab_addr+'"', subm_lab_sample_id, '"'+authors+'"']
        metaFh.write(u",".join(row))
        metaFh.write(u"\n")
    metaFh.close()
    logging.info("Wrote GISAID csv to %s" % metaFh.name)

def removeStraySeqsOrMeta(seqs, meta):
    " skips seqs without meta and meta without a seq "
    newSeqs = []
    seqIds = set()
    for seqId, seq in seqs:
        seqMeta = meta.get(seqId)

        if seqMeta is None:
            logging.error("Skipping fasta sequence with ID %s - cannot find it "
                "in the meta annotation table" % repr(seqId))
            continue

        newSeqs.append( (seqId, seq) )
        seqIds.add(seqId)

    newMeta = OrderedDict()
    for seqId, metaDict in meta.items():
        if seqId not in seqIds:
            logging.error("Skipping meta annotation with ID %s - cannot find it "
                "in the sequence file" % repr(seqId))
            continue
        newMeta[seqId] = metaDict

    return newSeqs, newMeta

def upNcbi(zipFname, xmlFname, isProd):
    " upload the zip files onto the genbank ftp server, by default as a testing submission "
    cf = getConfig()
    from ftplib import FTP
    host = "ftp-private.ncbi.nlm.nih.gov"
    logging.info("Connecting to %s" % host)
    ftp = FTP(host, cf["ncbiUser"], cf["ncbiPass"])

    if isProd:
        dirName = "Production"
    else:
        dirName = "Test"

    logging.info("CWD %s" % dirName)
    ftp.cwd(dirName)

    subDir = now()
    ftp.mkd(subDir)
    ftp.cwd(subDir)
    logging.info("make directory %s" % subDir)

    logging.info("Uploading "+zipFname)
    f1 = open(zipFname,'rb')
    ftp.storbinary('STOR genbankFtp.zip', f1)
    f1.close()

    logging.info("Uploading "+xmlFname)
    f2 = open(xmlFname,'rb')
    ftp.storbinary('STOR submission.xml', f2)
    f2.close()

    logging.info("Creating submit.ready")
    with StringIO() as tmpFh:
        tmpFh.write(u"")
        ftp.storbinary('STOR submit.ready', tmpFh)

    ftp.quit()

def upEnaSeq(seqs, meta, asmUrl, auth):
    " upload sequences to ENA "
    logging.info("Starting upload to %s" % asmUrl)

    cf = getConfig()
    for (seqId, seq) in seqs:
        logging.info("Uploading sequence %s" % seqId)
        seqMeta = meta[seqId]
        trimCount, seq = trimSeq(seqId, seq)

        data = {
            'name': seqMeta["isolate"][:37],
            'study': cf["enaProj"],
            'sample': seqMeta["isolate"],
            'alias': seqMeta["isolate"],
            'coverage': 100,
            'program': 'unknown',
            'platform': cf["enaPlatform"],
            'sequence': seq
        }
        jsonStr = json.dumps(data, indent=4)

        headers = {'accept': 'application/json', 'Content-Type': 'application/json'}

        resp = requests.post(asmUrl, data=jsonStr, auth=auth, headers=headers)
        if resp.status_code != 200:
            logging.warning('error submitting sequence: ' + seqId + \
                ' with: ' + str(resp.status_code ) +' ' +  str(resp.text ))
            resp = requests.post(asmUrl+ '/validate', data=jsonStr, auth=auth, headers=headers)
            logging.warning('validate reponse is: ' + str(resp.text ))
            logging.warning('validate content is: ' + str(resp.content ))
            #ex = 'An error occurred in "submitting assembly" in statement: {}: "{}"'.format(str(response.status_code ),str(response.content))
            errAbort("seq upload failed")

def makeEnaSubmitXml():
    " return the template XML to add seqs to ENA "
    return """<?xml version="1.0" encoding="UTF-8"?>
    <SUBMISSION>
       <ACTIONS>
          <ACTION>
            <ADD/>
          </ACTION>
       </ACTIONS>
    </SUBMISSION>"""

def writeEnaXml(meta, ofh):
    " create the ENA XML file with the sample meta (not sequences)"
    cf = getConfig()
    centerName = cf["enaCenter"]
    collectorName = cf["enaCollector"]
    collInst = cf["enaCollInst"]
    country = cf["enaCountry"]
    region = cf["enaRegion"]
    host = cf["enaHost"]

    ofh.write("<SAMPLE_SET>\n")
    for seqId, seqMeta in meta.items():
        ofh.write('  <SAMPLE alias="%s" center_name = "%s">\n' % (seqMeta["isolate"], centerName))
        ofh.write('    <TITLE>Molecular surveillance of SARS-CoV-2</TITLE>\n')
        ofh.write('    <SAMPLE_NAME>\n')
        ofh.write('      <TAXON_ID>2697049</TAXON_ID>\n')
        ofh.write('      <SCIENTIFIC_NAME>Severe acute respiratory syndrome coronavirus 2</SCIENTIFIC_NAME>\n')
        ofh.write('    </SAMPLE_NAME>\n')
        ofh.write('    <SAMPLE_ATTRIBUTES>\n')

        # described here: https://www.ebi.ac.uk/ena/browser/view/ERC000033
        attributes = {
            "ENA-CHECKLIST" : "ERC000033",
            "collector name" : collectorName,
            "collecting institution" : collInst,
            "geographic location (country and/or sea)" : country,
            "geographic location (region and locality)" : region,
            "collection date" : seqMeta["date"],
            "host common name" : host,
            "sample capture status" : "active surveillance in response to outbreak",
            "host scientific name" : "Homo sapiens",
            "host subject id" : seqId, # not correct, but we have no other identifier
            "host health state" : "diseased",
            "host sex" : "not provided",
            "isolate" : seqMeta["isolate"],
        }

        for tag, value in attributes.items():
            ofh.write('      <SAMPLE_ATTRIBUTE>')
            ofh.write('<TAG>%s</TAG>' % tag)
            ofh.write('<VALUE>%s</VALUE>' % value)
            ofh.write('</SAMPLE_ATTRIBUTE>\n')
        ofh.write("    </SAMPLE_ATTRIBUTES>\n")
        ofh.write("  </SAMPLE>\n\n")

    ofh.write("</SAMPLE_SET>\n")
    logging.info("Wrote %s" % ofh.name)

def upEnaSample(xmlFname, upUrl, sampleLogFn, auth):
    " upload sample meta data to ENA "
    # see https://ena-docs.readthedocs.io/en/latest/submit/samples/programmatic.html
    subXml = makeEnaSubmitXml()
    logging.info("Sending %s to %s" % (xmlFname, upUrl))
    fileInfo = {'SAMPLE': io.open(xmlFname), 'SUBMISSION': subXml}
    resp = requests.post(url=upUrl, files=fileInfo, auth=auth)

    assert(not isfile(sampleLogFn)) # submission receipt file must not exist yet
    ofh = io.open(sampleLogFn, "wt")
    logging.info("Wrote receipt to %s" % sampleLogFn)
    ofh.write(resp.content.decode("utf8"))

def upEna(sampleFname, seqFname, metaFname, seqLog, sampleLogFn, isProd):
    " upload using webin ENA API "
    seqs = parseFasta(seqFname)
    meta = readMeta(metaFname)

    baseUrl = "https://wwwdev.ebi.ac.uk/ena/submit/"
    if isProd:
        baseUrl = "https://www.ebi.ac.uk/ena/submit/"

    cf = getConfig()
    auth = (cf["enaUser"], cf["enaPass"])

    sampleUpUrl = baseUrl+"drop-box/submit"
    upEnaSample(sampleFname, sampleUpUrl, sampleLogFn, auth)

    seqUpUrl = baseUrl + "webin-cli/api/v1/genome/covid-19"
    upEnaSeq(seqs, meta, seqUpUrl, auth)

def main():
    args, options = parseArgs()

    cmd = args[0]

    outFmts = getFormats(options.format)

    if cmd=="conv":
        faFname, metaFname, outDir = args[1:]
        seqs = list(parseFasta(faFname))
        meta = readMeta(metaFname)
        logging.info("Read %d sequences and %d annotation rows" % (len(seqs), len(meta)))
        seqs, meta = removeStraySeqsOrMeta(seqs, meta)

        if options.skipFile:
            seqs, meta, skipSeqs, skipMeta = filterAll(options.skipFile, seqs, meta)

        if not isdir(outDir):
            os.mkdir(outDir)
            logging.info("Created directory %s" % outDir)

        if "ncbi-sep" in outFmts:
            # raw fasta file
            seqFn = join(outDir, "genbankSeq.fa")
            writeFasta(seqs, io.open(seqFn, "wt"))
            # raw meta file
            metaFn = join(outDir, "genbankSource.tsv")
            gbMeta = metaToGenbank(meta)
            writeMetaTsv(meta, io.open(metaFn, "wt"))

        if "ncbi" in outFmts:
            # combined genbank seq + source tags file
            gbOutFn = join(outDir, "genbankSeqAndSource.fa")
            writeGenbankTagFa(seqs, meta, gbOutFn)

            #if len(skipSeqs)!=0:
                #gbSkipFn = outBase+"genbank.skip.fa"
                #writeGenbankTagFa(skipSeqs, skipMeta, gbSkipFn)

        if "ncbi-ftp" in outFmts:
            zipFname = join(outDir, "genbankFtp.zip")
            xmlFname = join(outDir, "submission.xml")
            writeGenbankFtpZip(seqs, meta, zipFname, xmlFname)

        if "gisaid" in outFmts:
            gisaidSeqFn = join(outDir, "gisaid.fa")
            gisaidMetaFn = join(outDir, "gisaid.csv")
            writeGisaidCsv(seqs, meta, gisaidSeqFn, gisaidMetaFn)

        if "ena" in outFmts:
            sampleFn = join(outDir, "ena.xml")
            writeEnaXml(meta, io.open(sampleFn, "wt"))

    elif cmd=="up-ncbi":
        dataDir = args[1]
        zipFname = join(dataDir, "genbankFtp.zip")
        xmlFname = join(dataDir, "submission.xml")

        upNcbi(zipFname, xmlFname, options.prod)

    elif cmd=="up-ena":
        dataDir = args[1]
        seqFname = join(dataDir, "genbankSeq.fa")
        xmlFname = join(dataDir, "ena.xml")
        metaFname = join(dataDir, "genbankSource.tsv")

        nowStr = now()
        seqLog = join(dataDir, "enaReceiptSeq.%s.xml" % nowStr)
        sampleLog = join(dataDir, "enaReceiptSample.%s.xml" % nowStr)

        upEna(xmlFname, seqFname, metaFname, seqLog, sampleLog, options.prod)

main()
